{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "china.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJfNB6hOMSPm",
        "outputId": "8bc1c87e-9c70-4d21-8f7c-1e9c3847dfa6"
      },
      "source": [
        "!gdown --id '151UEEw6bTO3g6JNdNFrpfPC2TAFUNk-0' --output china.xlsx"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=151UEEw6bTO3g6JNdNFrpfPC2TAFUNk-0\n",
            "To: /content/china.xlsx\n",
            "\r  0% 0.00/103k [00:00<?, ?B/s]\r100% 103k/103k [00:00<00:00, 70.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYAkLO_kMZZV"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORdSZiRONN7v"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7scyQ-a_NOKl"
      },
      "source": [
        "def random_seed_setup(seed):\n",
        "    # For reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        return 'cuda'\n",
        "    else:\n",
        "        return 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 0.01)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure()\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN_sSkHANOWN"
      },
      "source": [
        "class China(Dataset):\n",
        "    def __init__(self,\n",
        "                 input_array,\n",
        "                 mode='train',\n",
        "                 normalize='none',\n",
        "                 target_only=False,\n",
        "                 norm_mean=None,\n",
        "                 norm_std=None):\n",
        "        self.mode = mode\n",
        "\n",
        "      \n",
        "        data = np.array(input_array[0:])[:, 0:].astype(float)\n",
        "        \n",
        "        if not target_only:\n",
        "            feats = list(range(1))\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "            \n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "            else:\n",
        "                indices = list(range(len(data)))\n",
        "                # only when mode == 'train_all' (i.e., using all data for training)\n",
        "            \n",
        "            data = data[indices]\n",
        "            target = target[indices]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data)\n",
        "            self.target = torch.FloatTensor(target)\n",
        "        \n",
        "        self.norm_mean = None\n",
        "        self.norm_std = None\n",
        "\n",
        "        if normalize == 'self':\n",
        "            self.norm_mean = self.data.mean(dim=0).unsqueeze(0)\n",
        "            self.norm_std = self.data.std(dim=0).unsqueeze(0)\n",
        "            self.data = (self.data - self.norm_mean) / self.norm_std\n",
        "\n",
        "        if normalize == 'given' and (norm_mean is not None) and (norm_std is not None):\n",
        "            self.data = (self.data - norm_mean) / norm_std\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of the Covid19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, self.data.shape[0], self.data.shape[1]))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.mode in ['train', 'dev', 'train_all']:\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHQ6jXomNOhc"
      },
      "source": [
        "def prep_dataloader(tr_path, tt_path, batch_size, n_jobs=0, target_only=False):\n",
        "    tr_dataset = China(\n",
        "        tr_path, mode='train_all',\n",
        "        normalize='self', \n",
        "        target_only=target_only)\n",
        "\n",
        "    dv_dataset = China(\n",
        "        tr_path, mode='dev',\n",
        "        normalize='given', \n",
        "        target_only=target_only,\n",
        "        norm_mean=tr_dataset.norm_mean,\n",
        "        norm_std=tr_dataset.norm_std)\n",
        "\n",
        "    tt_dataset = China(\n",
        "        tt_path, mode='test',\n",
        "        normalize='given',\n",
        "        target_only=target_only,\n",
        "        norm_mean=tr_dataset.norm_mean,\n",
        "        norm_std=tr_dataset.norm_std)\n",
        "    \n",
        "    tr_dataloader = DataLoader(\n",
        "        tr_dataset, batch_size,\n",
        "        shuffle=True, drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)\n",
        "    \n",
        "    dv_dataloader = DataLoader(\n",
        "        dv_dataset, batch_size,\n",
        "        shuffle=False, drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)\n",
        "\n",
        "    tt_dataloader = DataLoader(\n",
        "        tt_dataset, batch_size,\n",
        "        shuffle=False, drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)\n",
        "    \n",
        "    return tr_dataloader, dv_dataloader, tt_dataloader"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RPM2fFgNOsc"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim, l2_reg=0.):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 31),\n",
        "            nn.RReLU(),  # randomized ReLU\n",
        "            nn.Linear(31, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target, is_train=True):\n",
        "        ''' Calculate loss '''\n",
        "        total_loss = 0\n",
        "\n",
        "        mse_loss = self.criterion(pred, target)\n",
        "        total_loss += mse_loss\n",
        "        if is_train and self.l2_reg > 0.:\n",
        "            reg_loss = 0\n",
        "            for param in self.parameters():\n",
        "                reg_loss += torch.norm(param, p=2)\n",
        "            total_loss += reg_loss * self.l2_reg\n",
        "        \n",
        "        return total_loss, mse_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYTqv308RXKm"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    n_epochs = config['n_epochs']\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    loss_record = {'train': [], 'dev': []}\n",
        "    min_mse = 1000.\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()\n",
        "        for i, (x, y) in enumerate(tr_set):\n",
        "            optimizer.zero_grad()\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss, mse_loss = model.cal_loss(pred, y, is_train=True)\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_record['train'].append(total_loss.detach().cpu().item())\n",
        "\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "        \n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "\n",
        "    return min_mse, loss_record\n",
        "\n",
        "def dev(dv_set, model, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "            _, mse_loss = model.cal_loss(pred, y, is_train=False)\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)\n",
        "    total_loss = total_loss / len(dv_set.dataset)\n",
        "   # print('total_loss =', total_loss)\n",
        "    return total_loss"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WVMparRXa2"
      },
      "source": [
        "device = random_seed_setup(42097)\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False\n",
        "\n",
        "config = {\n",
        "    'n_epochs': 10000,                  # maximum number of epochs\n",
        "    'batch_size': 20,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,                # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky9DGP1VRXqd"
      },
      "source": [
        "df = pd.read_excel('china.xlsx')\n",
        "input = []\n",
        "for i in range(2, df.shape[0]):\n",
        "    input.append([df.iat[i, 0], df.iat[i, 6]])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D7aOnSFRX4k",
        "outputId": "526c8430-fe7c-42c4-bf6b-04809bc8cc89"
      },
      "source": [
        "len(input)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcd4UMT_RYGt",
        "outputId": "b48aa7e0-1eb2-4b2f-ad4d-7ea69761a426"
      },
      "source": [
        "input[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20527, 53]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjq_Jb6rRYUE",
        "outputId": "0cf20764-63a9-49c8-893b-fb6f46212ba6"
      },
      "source": [
        "tr_set, dv_set, tt_set = prep_dataloader(\n",
        "    input, input, config['batch_size'], \n",
        "    target_only=target_only)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished reading the train_all set of the Covid19 Dataset (556 samples found, each dim = 1)\n",
            "Finished reading the dev set of the Covid19 Dataset (56 samples found, each dim = 1)\n",
            "Finished reading the test set of the Covid19 Dataset (556 samples found, each dim = 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeqHDVrNTsDl"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim, 0.001).to(device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhle36I7TsS8",
        "outputId": "af6d4d9f-3e61-4f98-cbbb-39b242e94623"
      },
      "source": [
        "model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished training after 201 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NRTjjB1lTsgl",
        "outputId": "f4731203-3954-4b60-ba51-a08a50b67fb1"
      },
      "source": [
        "plot_learning_curve(model_loss_record[1], title='deep model')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p-ypWXBUKIW",
        "outputId": "f050eac5-fe08-4ff4-bad3-7c9555236e93"
      },
      "source": [
        "model_loss_record[1]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev': [nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan],\n",
              " 'train': [535006.5,\n",
              "  1612.45703125,\n",
              "  141393.1875,\n",
              "  455036.21875,\n",
              "  184564.703125,\n",
              "  1783188.75,\n",
              "  831143.6875,\n",
              "  1153519.625,\n",
              "  215443.8125,\n",
              "  1169650.0,\n",
              "  1342650.375,\n",
              "  186952.46875,\n",
              "  2082064.5,\n",
              "  947510.25,\n",
              "  2926584.25,\n",
              "  399916.15625,\n",
              "  40660924.0,\n",
              "  19329150976.0,\n",
              "  5.157662810850722e+18,\n",
              "  inf,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  ...]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tb9ylp6UMRv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}